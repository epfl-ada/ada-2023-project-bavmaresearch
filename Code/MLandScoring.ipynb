{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_genres</th>\n",
       "      <th>Main_genre</th>\n",
       "      <th>Main_language</th>\n",
       "      <th>Top_genres</th>\n",
       "      <th>Main_country</th>\n",
       "      <th>Main_continent</th>\n",
       "      <th>Plot_summary</th>\n",
       "      <th>...</th>\n",
       "      <th>Estimated_Budget</th>\n",
       "      <th>IMDb</th>\n",
       "      <th>Oscar_Wins</th>\n",
       "      <th>Nominations</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Inflation_adjusted_profit</th>\n",
       "      <th>nconst</th>\n",
       "      <th>Director_name</th>\n",
       "      <th>capped_profit</th>\n",
       "      <th>Successful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11509</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>2185372302</td>\n",
       "      <td>194.0</td>\n",
       "      <td>{\"/m/0fx2s\": \"Tragedy\", \"/m/04xvh5\": \"Costume ...</td>\n",
       "      <td>['Tragedy', 'Costume drama', 'Historical ficti...</td>\n",
       "      <td>Multilingual</td>\n",
       "      <td>Action/Adventure</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>In 1996, treasure hunter Brock Lovett and his...</td>\n",
       "      <td>...</td>\n",
       "      <td>200000000</td>\n",
       "      <td>tt0120338</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>1985372302</td>\n",
       "      <td>2.928104e+09</td>\n",
       "      <td>nm0000116</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>1119929521</td>\n",
       "      <td>250.0</td>\n",
       "      <td>{\"/m/0hj3n2k\": \"Fantasy Adventure\", \"/m/03k9fj...</td>\n",
       "      <td>['Fantasy Adventure', 'Adventure', 'Epic', 'Ac...</td>\n",
       "      <td>Multilingual</td>\n",
       "      <td>Action/Adventure</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gandalf, Aragorn, Legolas, Gimli, Th√©oden, Ga...</td>\n",
       "      <td>...</td>\n",
       "      <td>94000000</td>\n",
       "      <td>tt0167260</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1025929521</td>\n",
       "      <td>1.320270e+09</td>\n",
       "      <td>nm0001392</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12347</th>\n",
       "      <td>Ben-Hur</td>\n",
       "      <td>146900000</td>\n",
       "      <td>219.0</td>\n",
       "      <td>{\"/m/03g3w\": \"History\", \"/m/02l7c8\": \"Romance ...</td>\n",
       "      <td>['History', 'Romance Film', 'Action', 'Drama',...</td>\n",
       "      <td>English Language</td>\n",
       "      <td>Action/Adventure</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>In AD 26, Judah Ben-Hur  is a wealthy prince a...</td>\n",
       "      <td>...</td>\n",
       "      <td>15000000</td>\n",
       "      <td>tt0052618</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>131900000</td>\n",
       "      <td>1.071201e+09</td>\n",
       "      <td>nm0943758</td>\n",
       "      <td>William Wyler</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13786</th>\n",
       "      <td>West Side Story</td>\n",
       "      <td>43700000</td>\n",
       "      <td>152.0</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/04t36\": \"Mus...</td>\n",
       "      <td>['Crime Fiction', 'Musical', 'Drama', 'Romance...</td>\n",
       "      <td>Multilingual</td>\n",
       "      <td>Family</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Although the plot summary here is divided into...</td>\n",
       "      <td>...</td>\n",
       "      <td>6000000</td>\n",
       "      <td>tt0055614</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>37700000</td>\n",
       "      <td>2.985766e+08</td>\n",
       "      <td>nm0730385</td>\n",
       "      <td>Jerome Robbins</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19556</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>400000000</td>\n",
       "      <td>234.0</td>\n",
       "      <td>{\"/m/060__y\": \"Film adaptation\", \"/m/04xvh5\": ...</td>\n",
       "      <td>['Film adaptation', 'Costume drama', 'Roadshow...</td>\n",
       "      <td>English Language</td>\n",
       "      <td>Drama</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>The film opens on a large cotton plantation c...</td>\n",
       "      <td>...</td>\n",
       "      <td>4000000</td>\n",
       "      <td>tt0031381</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>396000000</td>\n",
       "      <td>6.740385e+09</td>\n",
       "      <td>nm0281808</td>\n",
       "      <td>Victor Fleming</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16366</th>\n",
       "      <td>Speed</td>\n",
       "      <td>350448145</td>\n",
       "      <td>115.0</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/03btsm8\": \"Actio...</td>\n",
       "      <td>['Thriller', 'Action/Adventure', 'Action', 'Cr...</td>\n",
       "      <td>Multilingual</td>\n",
       "      <td>Drama</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>An unidentified man  traps several businesspeo...</td>\n",
       "      <td>...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>tt0111257</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>320448145</td>\n",
       "      <td>5.118007e+08</td>\n",
       "      <td>nm0000957</td>\n",
       "      <td>Jan de Bont</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12229</th>\n",
       "      <td>Star Trek</td>\n",
       "      <td>385494555</td>\n",
       "      <td>126.0</td>\n",
       "      <td>{\"/m/023pxm\": \"Reboot\", \"/m/06n90\": \"Science F...</td>\n",
       "      <td>['Reboot', 'Science Fiction', 'Action', 'Adven...</td>\n",
       "      <td>English Language</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In 2233, the Federation starship USS Kelvin i...</td>\n",
       "      <td>...</td>\n",
       "      <td>150000000</td>\n",
       "      <td>tt0796366</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>235494555</td>\n",
       "      <td>2.598623e+08</td>\n",
       "      <td>nm0009190</td>\n",
       "      <td>J.J. Abrams</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28846</th>\n",
       "      <td>Capote</td>\n",
       "      <td>49233161</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/017fp\": \"Bio...</td>\n",
       "      <td>['Crime Fiction', 'Biography', 'Crime Drama', ...</td>\n",
       "      <td>English Language</td>\n",
       "      <td>Drama</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The film opens in Kansas with the discovery of...</td>\n",
       "      <td>...</td>\n",
       "      <td>7000000</td>\n",
       "      <td>tt0379725</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>42233161</td>\n",
       "      <td>5.119582e+07</td>\n",
       "      <td>nm0587955</td>\n",
       "      <td>Bennett Miller</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33499</th>\n",
       "      <td>The Help</td>\n",
       "      <td>211608112</td>\n",
       "      <td>145.0</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\", \"/m/04xvlr\": \"Period p...</td>\n",
       "      <td>['Drama', 'Period piece', 'Comedy-drama']</td>\n",
       "      <td>English Language</td>\n",
       "      <td>Drama</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aibileen Clark  is a middle-aged black maid wh...</td>\n",
       "      <td>...</td>\n",
       "      <td>25000000</td>\n",
       "      <td>tt1454029</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>186608112</td>\n",
       "      <td>1.963948e+08</td>\n",
       "      <td>nm0853238</td>\n",
       "      <td>Tate Taylor</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39849</th>\n",
       "      <td>The Gay Divorcee</td>\n",
       "      <td>1774000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>{\"/m/06cvj\": \"Romantic comedy\", \"/m/06qm3\": \"S...</td>\n",
       "      <td>['Romantic comedy', 'Screwball comedy', 'Black...</td>\n",
       "      <td>English Language</td>\n",
       "      <td>Family</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Mimi Glossop  arrives in England to seek a div...</td>\n",
       "      <td>...</td>\n",
       "      <td>520000</td>\n",
       "      <td>tt0025164</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1254000</td>\n",
       "      <td>2.218185e+07</td>\n",
       "      <td>nm0762263</td>\n",
       "      <td>Mark Sandrich</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Movie_name  \\\n",
       "11509                                        Titanic   \n",
       "41728  The Lord of the Rings: The Return of the King   \n",
       "12347                                        Ben-Hur   \n",
       "13786                                West Side Story   \n",
       "19556                             Gone with the Wind   \n",
       "...                                              ...   \n",
       "16366                                          Speed   \n",
       "12229                                      Star Trek   \n",
       "28846                                         Capote   \n",
       "33499                                       The Help   \n",
       "39849                               The Gay Divorcee   \n",
       "\n",
       "       Movie_box_office_revenue  Movie_runtime  \\\n",
       "11509                2185372302          194.0   \n",
       "41728                1119929521          250.0   \n",
       "12347                 146900000          219.0   \n",
       "13786                  43700000          152.0   \n",
       "19556                 400000000          234.0   \n",
       "...                         ...            ...   \n",
       "16366                 350448145          115.0   \n",
       "12229                 385494555          126.0   \n",
       "28846                  49233161           98.0   \n",
       "33499                 211608112          145.0   \n",
       "39849                   1774000          105.0   \n",
       "\n",
       "                                            Movie_genres  \\\n",
       "11509  {\"/m/0fx2s\": \"Tragedy\", \"/m/04xvh5\": \"Costume ...   \n",
       "41728  {\"/m/0hj3n2k\": \"Fantasy Adventure\", \"/m/03k9fj...   \n",
       "12347  {\"/m/03g3w\": \"History\", \"/m/02l7c8\": \"Romance ...   \n",
       "13786  {\"/m/0lsxr\": \"Crime Fiction\", \"/m/04t36\": \"Mus...   \n",
       "19556  {\"/m/060__y\": \"Film adaptation\", \"/m/04xvh5\": ...   \n",
       "...                                                  ...   \n",
       "16366  {\"/m/01jfsb\": \"Thriller\", \"/m/03btsm8\": \"Actio...   \n",
       "12229  {\"/m/023pxm\": \"Reboot\", \"/m/06n90\": \"Science F...   \n",
       "28846  {\"/m/0lsxr\": \"Crime Fiction\", \"/m/017fp\": \"Bio...   \n",
       "33499  {\"/m/07s9rl0\": \"Drama\", \"/m/04xvlr\": \"Period p...   \n",
       "39849  {\"/m/06cvj\": \"Romantic comedy\", \"/m/06qm3\": \"S...   \n",
       "\n",
       "                                              Main_genre     Main_language  \\\n",
       "11509  ['Tragedy', 'Costume drama', 'Historical ficti...      Multilingual   \n",
       "41728  ['Fantasy Adventure', 'Adventure', 'Epic', 'Ac...      Multilingual   \n",
       "12347  ['History', 'Romance Film', 'Action', 'Drama',...  English Language   \n",
       "13786  ['Crime Fiction', 'Musical', 'Drama', 'Romance...      Multilingual   \n",
       "19556  ['Film adaptation', 'Costume drama', 'Roadshow...  English Language   \n",
       "...                                                  ...               ...   \n",
       "16366  ['Thriller', 'Action/Adventure', 'Action', 'Cr...      Multilingual   \n",
       "12229  ['Reboot', 'Science Fiction', 'Action', 'Adven...  English Language   \n",
       "28846  ['Crime Fiction', 'Biography', 'Crime Drama', ...  English Language   \n",
       "33499          ['Drama', 'Period piece', 'Comedy-drama']  English Language   \n",
       "39849  ['Romantic comedy', 'Screwball comedy', 'Black...  English Language   \n",
       "\n",
       "             Top_genres               Main_country Main_continent  \\\n",
       "11509  Action/Adventure   United States of America            USA   \n",
       "41728  Action/Adventure   United States of America            NaN   \n",
       "12347  Action/Adventure   United States of America            USA   \n",
       "13786            Family   United States of America            USA   \n",
       "19556             Drama   United States of America            USA   \n",
       "...                 ...                        ...            ...   \n",
       "16366             Drama   United States of America            USA   \n",
       "12229           Fiction   United States of America            NaN   \n",
       "28846             Drama   United States of America            NaN   \n",
       "33499             Drama   United States of America            NaN   \n",
       "39849            Family   United States of America            USA   \n",
       "\n",
       "                                            Plot_summary  ...  \\\n",
       "11509   In 1996, treasure hunter Brock Lovett and his...  ...   \n",
       "41728   Gandalf, Aragorn, Legolas, Gimli, Th√©oden, Ga...  ...   \n",
       "12347  In AD 26, Judah Ben-Hur  is a wealthy prince a...  ...   \n",
       "13786  Although the plot summary here is divided into...  ...   \n",
       "19556   The film opens on a large cotton plantation c...  ...   \n",
       "...                                                  ...  ...   \n",
       "16366  An unidentified man  traps several businesspeo...  ...   \n",
       "12229   In 2233, the Federation starship USS Kelvin i...  ...   \n",
       "28846  The film opens in Kansas with the discovery of...  ...   \n",
       "33499  Aibileen Clark  is a middle-aged black maid wh...  ...   \n",
       "39849  Mimi Glossop  arrives in England to seek a div...  ...   \n",
       "\n",
       "       Estimated_Budget       IMDb  Oscar_Wins  Nominations      Profit  \\\n",
       "11509         200000000  tt0120338          11           14  1985372302   \n",
       "41728          94000000  tt0167260          11           11  1025929521   \n",
       "12347          15000000  tt0052618          11           12   131900000   \n",
       "13786           6000000  tt0055614          10           11    37700000   \n",
       "19556           4000000  tt0031381           8           13   396000000   \n",
       "...                 ...        ...         ...          ...         ...   \n",
       "16366          30000000  tt0111257           2            3   320448145   \n",
       "12229         150000000  tt0796366           1            4   235494555   \n",
       "28846           7000000  tt0379725           1            5    42233161   \n",
       "33499          25000000  tt1454029           1            4   186608112   \n",
       "39849            520000  tt0025164           1            5     1254000   \n",
       "\n",
       "      Inflation_adjusted_profit     nconst   Director_name  capped_profit  \\\n",
       "11509              2.928104e+09  nm0000116   James Cameron   1.160929e+07   \n",
       "41728              1.320270e+09  nm0001392   Peter Jackson   1.160929e+07   \n",
       "12347              1.071201e+09  nm0943758   William Wyler   1.160929e+07   \n",
       "13786              2.985766e+08  nm0730385  Jerome Robbins   1.160929e+07   \n",
       "19556              6.740385e+09  nm0281808  Victor Fleming   1.160929e+07   \n",
       "...                         ...        ...             ...            ...   \n",
       "16366              5.118007e+08  nm0000957     Jan de Bont   1.160929e+07   \n",
       "12229              2.598623e+08  nm0009190     J.J. Abrams   1.160929e+07   \n",
       "28846              5.119582e+07  nm0587955  Bennett Miller   1.160929e+07   \n",
       "33499              1.963948e+08  nm0853238     Tate Taylor   1.160929e+07   \n",
       "39849              2.218185e+07  nm0762263   Mark Sandrich   1.160929e+07   \n",
       "\n",
       "       Successful  \n",
       "11509        10.0  \n",
       "41728         9.9  \n",
       "12347         9.8  \n",
       "13786         9.3  \n",
       "19556         9.1  \n",
       "...           ...  \n",
       "16366         5.9  \n",
       "12229         5.9  \n",
       "28846         5.9  \n",
       "33499         5.9  \n",
       "39849         5.9  \n",
       "\n",
       "[300 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "try:\n",
    "    # Reading the data from a CSV file into a pandas DataFrame\n",
    "    df_avec_successful = pd.read_csv('../Datasets/movies_cleaned_dataset.csv')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "    # Handle the exception (e.g., exit the script or log an error)\n",
    "    exit()\n",
    "\n",
    "# Filling missing values for specific columns with their mean\n",
    "columns_to_fill = ['Inflation_adjusted_profit', 'averageRating', 'Oscar_Wins', 'Nominations']\n",
    "for column in columns_to_fill:\n",
    "    df_avec_successful[column].fillna(df_avec_successful[column].mean(), inplace=True)\n",
    "\n",
    "# Capping extreme values in 'Inflation adjusted profit' to reduce outlier impact\n",
    "# This reduces the impact of outliers by setting a threshold (90th percentile here)\n",
    "# Values above this threshold are set to the threshold value itself\n",
    "cap_threshold = df_avec_successful['Inflation_adjusted_profit'].quantile(0.90)\n",
    "df_avec_successful['capped_profit'] = df_avec_successful['Inflation_adjusted_profit'].clip(upper=cap_threshold)\n",
    "\n",
    "# Standardizing selected features (z-score normalization)\n",
    "z_features = {\n",
    "    'capped_profit': zscore(df_avec_successful['capped_profit']),\n",
    "    'averageRating': zscore(df_avec_successful['averageRating']),\n",
    "    'Oscar_Wins': zscore(df_avec_successful['Oscar_Wins']),\n",
    "    'Nominations': zscore(df_avec_successful['Nominations'])\n",
    "}\n",
    "\n",
    "# Assigning weights to standardized features\n",
    "weights = {\n",
    "    'capped_profit': 0.3,\n",
    "    'averageRating': 0.35,\n",
    "    'Oscar_Wins': 0.175,\n",
    "    'Nominations': 0.175\n",
    "}\n",
    "\n",
    "# Calculating a composite 'Successful' score using weighted features\n",
    "df_avec_successful['Successful'] = sum(weights[feature] * z_features[feature] for feature in weights)\n",
    "\n",
    "# Normalizing the 'Successful' score to a 0-10 scale for interpretability\n",
    "min_score = df_avec_successful['Successful'].min()\n",
    "max_score = df_avec_successful['Successful'].max()\n",
    "df_avec_successful['Successful'] = round((df_avec_successful['Successful'] - min_score) / (max_score - min_score) * 10, 1)\n",
    "\n",
    "# Sorting the DataFrame by 'Successful' score in descending order\n",
    "df_avec_successful.sort_values(by='Successful', ascending=False, inplace=True)\n",
    "\n",
    "# Display the top 300 rows\n",
    "df_avec_successful.head(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Release_Date</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>Estimated_Budget</th>\n",
       "      <th>Oscar_Wins</th>\n",
       "      <th>Nominations</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Inflation_adjusted_profit</th>\n",
       "      <th>capped_profit</th>\n",
       "      <th>Successful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.215500e+04</td>\n",
       "      <td>3.554400e+04</td>\n",
       "      <td>42155.000000</td>\n",
       "      <td>42155.000000</td>\n",
       "      <td>2.643600e+04</td>\n",
       "      <td>4.215500e+04</td>\n",
       "      <td>42155.000000</td>\n",
       "      <td>42155.000000</td>\n",
       "      <td>4.215500e+04</td>\n",
       "      <td>4.215500e+04</td>\n",
       "      <td>4.215500e+04</td>\n",
       "      <td>42155.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.309064e+06</td>\n",
       "      <td>1.285770e+02</td>\n",
       "      <td>1860.930376</td>\n",
       "      <td>6.268028</td>\n",
       "      <td>2.380605e+04</td>\n",
       "      <td>3.230446e+06</td>\n",
       "      <td>0.031693</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>6.078617e+06</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>9.680834e+05</td>\n",
       "      <td>4.53741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.334529e+07</td>\n",
       "      <td>5.724356e+03</td>\n",
       "      <td>478.466297</td>\n",
       "      <td>0.867840</td>\n",
       "      <td>9.685211e+04</td>\n",
       "      <td>1.477468e+07</td>\n",
       "      <td>0.326571</td>\n",
       "      <td>0.736461</td>\n",
       "      <td>4.449285e+07</td>\n",
       "      <td>8.851471e+07</td>\n",
       "      <td>9.150590e+06</td>\n",
       "      <td>0.33163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.250000e+08</td>\n",
       "      <td>-2.739096e+08</td>\n",
       "      <td>-2.739096e+08</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.600000e+01</td>\n",
       "      <td>1959.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>6.268028</td>\n",
       "      <td>1.483000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.100000e+02</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>7.910250e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.782275e+09</td>\n",
       "      <td>1.079281e+06</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>2.816055e+06</td>\n",
       "      <td>3.800000e+08</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.545275e+09</td>\n",
       "      <td>6.822472e+09</td>\n",
       "      <td>1.160929e+07</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Movie_box_office_revenue  Movie_runtime  Release_Date  averageRating  \\\n",
       "count              4.215500e+04   3.554400e+04  42155.000000   42155.000000   \n",
       "mean               9.309064e+06   1.285770e+02   1860.930376       6.268028   \n",
       "std                5.334529e+07   5.724356e+03    478.466297       0.867840   \n",
       "min                0.000000e+00   3.000000e-01      0.000000       1.200000   \n",
       "25%                0.000000e+00   8.600000e+01   1959.000000       6.200000   \n",
       "50%                0.000000e+00   9.600000e+01   1990.000000       6.268028   \n",
       "75%                0.000000e+00   1.100000e+02   2005.000000       6.600000   \n",
       "max                2.782275e+09   1.079281e+06   2014.000000       9.800000   \n",
       "\n",
       "           numVotes  Estimated_Budget    Oscar_Wins   Nominations  \\\n",
       "count  2.643600e+04      4.215500e+04  42155.000000  42155.000000   \n",
       "mean   2.380605e+04      3.230446e+06      0.031693      0.078947   \n",
       "std    9.685211e+04      1.477468e+07      0.326571      0.736461   \n",
       "min    5.000000e+00      0.000000e+00      0.000000      0.000000   \n",
       "25%    3.350000e+02      0.000000e+00      0.000000      0.000000   \n",
       "50%    1.483000e+03      0.000000e+00      0.000000      0.000000   \n",
       "75%    7.910250e+03      0.000000e+00      0.000000      0.000000   \n",
       "max    2.816055e+06      3.800000e+08     11.000000     14.000000   \n",
       "\n",
       "             Profit  Inflation_adjusted_profit  capped_profit   Successful  \n",
       "count  4.215500e+04               4.215500e+04   4.215500e+04  42155.00000  \n",
       "mean   6.078617e+06               1.160929e+07   9.680834e+05      4.53741  \n",
       "std    4.449285e+07               8.851471e+07   9.150590e+06      0.33163  \n",
       "min   -2.250000e+08              -2.739096e+08  -2.739096e+08      0.00000  \n",
       "25%    0.000000e+00               0.000000e+00   0.000000e+00      4.50000  \n",
       "50%    0.000000e+00               0.000000e+00   0.000000e+00      4.50000  \n",
       "75%    0.000000e+00               0.000000e+00   0.000000e+00      4.70000  \n",
       "max    2.545275e+09               6.822472e+09   1.160929e+07     10.00000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avec_successful.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer_feature_names(column_transformer):\n",
    "    \"\"\"\n",
    "    Get feature names from a fitted ColumnTransformer.\n",
    "    \"\"\"\n",
    "    output_features = []\n",
    "\n",
    "    for name, pipe, features in column_transformer.transformers_:\n",
    "        if name == 'remainder':\n",
    "            # If the remainder is a passthrough, its feature names are the same as the column names\n",
    "            if pipe == 'passthrough':\n",
    "                output_features.extend(features)\n",
    "            continue\n",
    "\n",
    "        # For transformers with a get_feature_names_out method\n",
    "        if hasattr(pipe, 'get_feature_names_out'):\n",
    "            transformer_features = pipe.get_feature_names_out(features)\n",
    "        else:\n",
    "            transformer_features = features\n",
    "\n",
    "        output_features.extend(transformer_features)\n",
    "\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Drama', 'Other', 'Family', 'Action/Adventure'], dtype='object', name='Top_genres')\n",
      "Index(['Drama', 'Other', 'Family', 'Action/Adventure'], dtype='object', name='Top_genres')\n",
      "999929292929292929292\n",
      "Index(['Drama', 'Other', 'Family', 'Action/Adventure'], dtype='object', name='Top_genres')\n",
      "Top_genres\n",
      "Drama               16115\n",
      "Other               13334\n",
      "Family               6265\n",
      "Action/Adventure     3544\n",
      "Horror               1554\n",
      "Fiction              1343\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "Analyzing genre: Drama - Data Points: 16115\n",
      "Optimal Runtime: 144.84 minutes\n",
      "MSE: 0.14296481470156197, RMSE: 0.378106882642411, R¬≤: 0.034469731152307004\n",
      "Top 4 Languages for Drama:\n",
      "                            Feature  Importance\n",
      "46       Main_language_Multilingual   50.494923\n",
      "28     Main_language_Hindi Language    3.042442\n",
      "20   Main_language_English Language    2.993256\n",
      "35  Main_language_Japanese Language    1.601940\n",
      "Top 4 Countries for Drama:\n",
      "                                    Feature  Importance\n",
      "179  Main_country_ United States of America   17.171030\n",
      "121                     Main_country_ India    4.536187\n",
      "178            Main_country_ United Kingdom    3.544076\n",
      "94                     Main_country_ Canada    0.939381\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "Analyzing genre: Other - Data Points: 13334\n",
      "Optimal Runtime: nan minutes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb#X10sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m \u001b[39m# Grid search for hyperparameter tuning\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb#X10sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(clf, param_grid_catboost, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb#X10sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb#X10sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m \u001b[39m# Best model after grid search\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb#X10sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m best_clf \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 427\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    429\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/catboost/core.py:5703\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5700\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5701\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5703\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[1;32m   5704\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[1;32m   5705\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[1;32m   5706\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/catboost/core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2320\u001b[0m         train_pool,\n\u001b[1;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2322\u001b[0m         params,\n\u001b[1;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2325\u001b[0m     )\n\u001b[1;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/catboost/core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "#from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data = df_avec_successful\n",
    "X = data.drop('Successful', axis=1)\n",
    "y = data['Successful']  # target\n",
    "\n",
    "#preprocessing steps for both categorical and numeric data. Categorical features are filled with a\n",
    "# placeholder value for any missing data and then one-hot encoded. Numeric features are imputed with their\n",
    "#  mean and then standardized. This transformed data is then used to train the RandomForestRegressor.\n",
    "#  Make sure to adjust the categorical_columns and numeric_columns lists to include all relevant features from your dataset.\n",
    "# Selecting categorical and numeric columns\n",
    "\n",
    "categorical_columns = ['Main_language', 'Main_country']  \n",
    "numeric_columns = ['Movie_runtime']  \n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())  # standardizing data\n",
    "])\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Get a list of unique genres\n",
    "top_genres = data['Top_genres'].value_counts().head(4).index\n",
    "print(top_genres)\n",
    "\n",
    "#top_genres = top_genres[1:]\n",
    "print(top_genres)\n",
    "print(\"999929292929292929292\")\n",
    "print(top_genres)\n",
    "print(data['Top_genres'].value_counts())\n",
    "# Analysis for each genre\n",
    "\n",
    "\n",
    "#OPTIMISATION\n",
    "\n",
    "# Hyperparameters grid for Random Forest\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "# Hyperparameters grid for CatBoost\n",
    "param_grid_catboost = {\n",
    "    'classifier__iterations': [100, 500, 1000],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.3],\n",
    "    'classifier__depth': [4, 6, 10],\n",
    "}\n",
    "# Analysis for each genre\n",
    "for genre in top_genres:\n",
    "    print(\"------------------------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------------------------\")\n",
    "    print(f\"Analyzing genre: {genre} - Data Points: {len(data[data['Top_genres'] == genre])}\")\n",
    "\n",
    "    genre_data = data[data['Top_genres'] == genre]\n",
    "    # Filter movies with success score greater than 7.5\n",
    "\n",
    "    successful_movies = genre_data[genre_data['Successful'] >= 7.5]\n",
    "    print(f\"Optimal Runtime: {successful_movies['Movie_runtime'].mean():.2f} minutes\")\n",
    "\n",
    "    try:\n",
    "        X_genre = genre_data[categorical_columns]\n",
    "        y_genre = genre_data['Successful']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_genre, y_genre, test_size=0.1, random_state=42)\n",
    "\n",
    "        clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('classifier', CatBoostRegressor(random_state=42, verbose=0))])\n",
    "\n",
    "        # Grid search for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(clf, param_grid_catboost, cv=3, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Best model after grid search\n",
    "        best_clf = grid_search.best_estimator_\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = best_clf.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = mse ** 0.5\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"MSE: {mse}, RMSE: {rmse}, R¬≤: {r2}\")\n",
    "\n",
    "        # Feature Importance Analysis\n",
    "        feature_importances = best_clf.named_steps['classifier'].feature_importances_\n",
    "        column_transformer = best_clf.named_steps['preprocessor']\n",
    "        feature_names = get_transformer_feature_names(column_transformer)\n",
    "       \n",
    "        # Ensure the number of feature names matches the number of feature importances\n",
    "        if len(feature_names) == len(feature_importances):\n",
    "            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "            sorted_feature_importance = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "            # Extracting and displaying top features excluding 'Main_language_missing'\n",
    "            top_languages = sorted_feature_importance[~sorted_feature_importance['Feature'].str.contains('Main_language_missing')]\n",
    "            top_languages = top_languages[top_languages['Feature'].str.contains('Main_language_')].head(4)\n",
    "            top_countries = sorted_feature_importance[sorted_feature_importance['Feature'].str.contains('Main_country_')].head(4)\n",
    "\n",
    "            print(f\"Top 4 Languages for {genre}:\\n{top_languages}\")\n",
    "            print(f\"Top 4 Countries for {genre}:\\n{top_countries}\")\n",
    "        else:\n",
    "            print(\"Number of feature names and feature importances do not match.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while analyzing genre {genre}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hb/c097qvmn7r37_y501thb23_80000gn/T/ipykernel_13144/1514118714.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features.dropna(inplace=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb#X11sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m scores \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb#X11sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb#X11sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     cv_scores \u001b[39m=\u001b[39m cross_val_score(model, X_train_scaled, y_train, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mneg_mean_squared_error\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb#X11sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     scores[model_name] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(cv_scores)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vale/ADAM3/ada-2023-project-bavmaresearch/Code/MLandScoring.ipynb#X11sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m# Find the best model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    574\u001b[0m )\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m    312\u001b[0m         X,\n\u001b[1;32m    313\u001b[0m         y,\n\u001b[1;32m    314\u001b[0m         scorers,\n\u001b[1;32m    315\u001b[0m         train,\n\u001b[1;32m    316\u001b[0m         test,\n\u001b[1;32m    317\u001b[0m         verbose,\n\u001b[1;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    319\u001b[0m         fit_params,\n\u001b[1;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    460\u001b[0m )(\n\u001b[1;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    462\u001b[0m         t,\n\u001b[1;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    464\u001b[0m         X,\n\u001b[1;32m    465\u001b[0m         y,\n\u001b[1;32m    466\u001b[0m         sample_weight,\n\u001b[1;32m    467\u001b[0m         i,\n\u001b[1;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[1;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m   1321\u001b[0m         X,\n\u001b[1;32m   1322\u001b[0m         y,\n\u001b[1;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1325\u001b[0m     )\n\u001b[1;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##ctors : cast : find best profile for each of the top 4 roles (sex, number of movies played in, age)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "df =  pd.read_csv('../Datasets/cast_processed.csv')\n",
    "df.dropna(inplace=True)\n",
    "#df = df[df['Successful'] >= 5.5]\n",
    "\n",
    "\n",
    "# Handling missing values (imputing with median)\n",
    "#df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "# Convert Release_Date to datetime and calculate actors' age\n",
    "df['Release_Date'] = pd.to_datetime(df['Release_Date'], format='%Y')\n",
    "current_year = pd.to_datetime('now').year\n",
    "\n",
    "##x=[current_year-int(y) for y in df['role_1_birth_year'] if not(y== '\\\\N') ]\n",
    "#print(x)\n",
    "   \n",
    "df['role_1_age'] = int(current_year) - pd.to_numeric(df['role_1_birth_year'], errors='coerce')\n",
    "df['role_2_age'] = int(current_year) - pd.to_numeric(df['role_2_birth_year'], errors='coerce')\n",
    "df['role_3_age'] = int(current_year)- pd.to_numeric(df['role_3_birth_year'], errors='coerce')\n",
    "df['role_4_age'] = int(current_year) - pd.to_numeric(df['role_4_birth_year'], errors='coerce')\n",
    "\n",
    "# Encode categorical data\n",
    "label_encoder = LabelEncoder()\n",
    "#Label encdoer veut une sequence de input uniforme selon le type\n",
    "df['role_1_sex'] = df['role_1_sex'].astype(str)\n",
    "df['role_2_sex'] = df['role_2_sex'].astype(str)\n",
    "df['role_3_sex'] = df['role_3_sex'].astype(str)\n",
    "df['role_4_sex'] = df['role_4_sex'].astype(str)\n",
    "\n",
    "\n",
    "df['role_1_sex'] = label_encoder.fit_transform(df['role_1_sex'])\n",
    "df['role_2_sex'] = label_encoder.fit_transform(df['role_2_sex'])\n",
    "df['role_3_sex'] = label_encoder.fit_transform(df['role_3_sex'])\n",
    "df['role_4_sex'] = label_encoder.fit_transform(df['role_4_sex'])\n",
    "\n",
    "\n",
    "# Selecting features and target\n",
    "features = df[['role_1_age', 'role_2_age', 'role_3_age', 'role_4_age',\n",
    "               'role_1_roles_count', 'role_2_roles_count', 'role_3_roles_count', 'role_4_roles_count',\n",
    "               'role_1_sex', 'role_2_sex', 'role_3_sex', 'role_4_sex']]\n",
    "target = df['Successful']\n",
    "\n",
    "features.dropna(inplace=True)\n",
    "#alignment but there is a loss of around 3K \n",
    "target = target.loc[features.index]\n",
    "\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"GradientBoosting\": XGBRegressor(random_state=42),\n",
    "    #\"LinearRegression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(random_state=42),\n",
    "    \"SVM\": SVR()\n",
    "}\n",
    "scores = {}\n",
    "for model_name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    scores[model_name] = np.mean(cv_scores)\n",
    "\n",
    "# Find the best model\n",
    "best_model_name = max(scores, key=scores.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Train and evaluate the best model\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")\n",
    "\n",
    "# Model Training\n",
    "# Using Random Forest Regressor as an example\n",
    "#rf = RandomForestRegressor(random_state=42)\n",
    "#df.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicting and Evaluating\n",
    "#y_pred = rf.predict(X_test_scaled)\n",
    "#mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "mse, r2\n",
    "if str(best_model_name) == \"LinearRegression\" or str(best_model_name) == \"Lasso\":\n",
    "    importances = np.abs(best_model.coef_)\n",
    "else:\n",
    "    importances = best_model.feature_importances_\n",
    "feature_names = features.columns\n",
    "\n",
    "# Create a DataFrame of feature importances\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "#print(importance_df)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Dictionary to store MSE values for each model at each fold\n",
    "model_mse = {name: [] for name in models.keys()}\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(X_train_scaled):\n",
    "    X_train_cv, X_test_cv = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        y_pred_cv = model.predict(X_test_cv)\n",
    "        mse = mean_squared_error(y_test_cv, y_pred_cv)\n",
    "        model_mse[name].append(mse)\n",
    "\n",
    "# Plotting the MSE evolution for each model\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, mse_scores in model_mse.items():\n",
    "    plt.plot(range(1, 11), mse_scores, marker='o', label=name)\n",
    "\n",
    "plt.title(\"MSE Evolution for Different Models Across Folds\")\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.xticks(range(1, 11))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Directors : find best profile for a director (age, number of movies directed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role_1 Profile:\n",
      "              Feature  Importance\n",
      "4  role_1_roles_count    0.110948\n",
      "0          role_1_age    0.106303\n",
      "8          role_1_sex    0.010743\n",
      "\n",
      "role_2 Profile:\n",
      "              Feature  Importance\n",
      "5  role_2_roles_count    0.126003\n",
      "1          role_2_age    0.108902\n",
      "9          role_2_sex    0.013164\n",
      "\n",
      "role_3 Profile:\n",
      "               Feature  Importance\n",
      "6   role_3_roles_count    0.135750\n",
      "2           role_3_age    0.109378\n",
      "10          role_3_sex    0.013822\n",
      "\n",
      "role_4 Profile:\n",
      "               Feature  Importance\n",
      "7   role_4_roles_count    0.133407\n",
      "3           role_4_age    0.117965\n",
      "11          role_4_sex    0.013615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_importances = rf.feature_importances_\n",
    "features = X_train.columns  # The names of your features\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "\n",
    "# Assuming your feature names are like 'role_1_age', 'role_1_roles_count', 'role_1_sex', etc.\n",
    "roles = ['role_1', 'role_2', 'role_3', 'role_4']\n",
    "profiles = {}\n",
    "\n",
    "for role in roles:\n",
    "    role_features = importance_df[importance_df['Feature'].str.startswith(role)]\n",
    "    profiles[role] = role_features.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print out the profiles\n",
    "for role, profile in profiles.items():\n",
    "    print(f\"{role} Profile:\")\n",
    "    print(profile)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse \n",
    "-In the code above we trained rf model such that it can predicts success rate based on thses features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Profile: {'role_1': {'age': 68, 'roles_count': 54, 'sex': 'M'}, 'role_2': {'age': 66, 'roles_count': 19, 'sex': 'F'}, 'role_3': {'age': 28, 'roles_count': 2, 'sex': 'M'}, 'role_4': {'age': 60, 'roles_count': 106, 'sex': 'M'}}\n",
      "Optimized Predicted Success Rate: 7.523999999999994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define initial guess for each role\n",
    "initial_guess = {\n",
    "    'role_1': {'age': 0, 'roles_count': 0, 'sex': 'M'},\n",
    "    'role_2': {'age': 30, 'roles_count': 10, 'sex': 'M'},\n",
    "    'role_3': {'age': 30, 'roles_count': 10, 'sex': 'M'},\n",
    "    'role_4': {'age': 30, 'roles_count': 10, 'sex': 'M'}\n",
    "}\n",
    "\n",
    "# Define ranges for age and roles_count\n",
    "age_range = range(10, 90)  # Age from 20 to 70\n",
    "role_count_range = range(1, 150)  # Role count from 1 to 100\n",
    "sex_range = ['M', 'F']  # Male and Female\n",
    "\n",
    "def optimize_profiles(model, initial_guess, iterations=1000):\n",
    "    best_profile = initial_guess.copy()\n",
    "    best_score = -np.inf\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        current_profile = best_profile.copy()\n",
    "\n",
    "        # Randomly adjust one of the parameters in one of the roles\n",
    "        role_to_adjust = random.choice(list(current_profile.keys()))\n",
    "        feature_to_adjust = random.choice(list(current_profile[role_to_adjust].keys()))\n",
    "\n",
    "        if feature_to_adjust == 'age':\n",
    "            current_profile[role_to_adjust]['age'] = random.choice(age_range)\n",
    "        elif feature_to_adjust == 'roles_count':\n",
    "            current_profile[role_to_adjust]['roles_count'] = random.choice(role_count_range)\n",
    "        elif feature_to_adjust == 'sex':\n",
    "            current_profile[role_to_adjust]['sex'] = random.choice(sex_range)\n",
    "\n",
    "        # Convert the current profile to a format suitable for the model\n",
    "        # This conversion will depend on how your model expects the input\n",
    "        model_input = convert_profile_to_model_input(current_profile)\n",
    "\n",
    "        # Predict the success rate\n",
    "        success_rate = model.predict([model_input])[0]\n",
    "\n",
    "        # Update best profile if current is better\n",
    "        if success_rate > best_score:\n",
    "            best_score = success_rate\n",
    "            best_profile = current_profile\n",
    "\n",
    "    return best_profile, best_score\n",
    "\n",
    "def convert_profile_to_model_input(profile):\n",
    "    # Convert the profile dictionary to a list or array in the order expected by the model\n",
    "    # This function needs to be defined based on how your model expects the input\n",
    "    # For example:\n",
    "    model_input = []\n",
    "    for role, features in profile.items():\n",
    "        model_input.append(features['age'])\n",
    "        model_input.append(features['roles_count'])\n",
    "        model_input.append(1 if features['sex'] == 'M' else 0)  # Assuming sex is binary and encoded as 1/0\n",
    "    return model_input\n",
    "\n",
    "\n",
    "optimized_profile, optimized_score = optimize_profiles(rf, initial_guess, iterations=5000)\n",
    "\n",
    "# Print the optimized profile and score\n",
    "print(\"Optimized Profile:\", optimized_profile)\n",
    "print(\"Optimized Predicted Success Rate:\", optimized_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Profile: {'role_1': {'age': 68, 'roles_count': 54, 'sex': 'M'}, 'role_2': {'age': 66, 'roles_count': 19, 'sex': 'F'}, 'role_3': {'age': 28, 'roles_count': 2, 'sex': 'M'}, 'role_4': {'age': 60, 'roles_count': 106, 'sex': 'M'}}\n",
      "Optimized Predicted Success Rate: 7.523999999999994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define initial guess for each role\n",
    "initial_guess = {\n",
    "    'role_1': {'age': 0, 'roles_count': 0, 'sex': 'M'},\n",
    "    'role_2': {'age': 30, 'roles_count': 10, 'sex': 'M'},\n",
    "    'role_3': {'age': 30, 'roles_count': 10, 'sex': 'M'},\n",
    "    'role_4': {'age': 30, 'roles_count': 10, 'sex': 'M'}\n",
    "}\n",
    "\n",
    "# Define ranges for age and roles_count\n",
    "age_range = range(10, 90)  # Age from 20 to 70\n",
    "role_count_range = range(1, 150)  # Role count from 1 to 100\n",
    "sex_range = ['M', 'F']  # Male and Female\n",
    "\n",
    "def optimize_profiles(model, initial_guess, iterations=1000):\n",
    "    best_profile = initial_guess.copy()\n",
    "    best_score = -np.inf\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        current_profile = best_profile.copy()\n",
    "\n",
    "        # Randomly adjust one of the parameters in one of the roles\n",
    "        role_to_adjust = random.choice(list(current_profile.keys()))\n",
    "        feature_to_adjust = random.choice(list(current_profile[role_to_adjust].keys()))\n",
    "\n",
    "        if feature_to_adjust == 'age':\n",
    "            current_profile[role_to_adjust]['age'] = random.choice(age_range)\n",
    "        elif feature_to_adjust == 'roles_count':\n",
    "            current_profile[role_to_adjust]['roles_count'] = random.choice(role_count_range)\n",
    "        elif feature_to_adjust == 'sex':\n",
    "            current_profile[role_to_adjust]['sex'] = random.choice(sex_range)\n",
    "\n",
    "        # Convert the current profile to a format suitable for the model\n",
    "        # This conversion will depend on how your model expects the input\n",
    "        model_input = convert_profile_to_model_input(current_profile)\n",
    "\n",
    "        # Predict the success rate\n",
    "        success_rate = model.predict([model_input])[0]\n",
    "\n",
    "        # Update best profile if current is better\n",
    "        if success_rate > best_score:\n",
    "            best_score = success_rate\n",
    "            best_profile = current_profile\n",
    "\n",
    "    return best_profile, best_score\n",
    "\n",
    "def convert_profile_to_model_input(profile):\n",
    "    # Convert the profile dictionary to a list or array in the order expected by the model\n",
    "    # This function needs to be defined based on how your model expects the input\n",
    "    # For example:\n",
    "    model_input = []\n",
    "    for role, features in profile.items():\n",
    "        model_input.append(features['age'])\n",
    "        model_input.append(features['roles_count'])\n",
    "        model_input.append(1 if features['sex'] == 'M' else 0)  # Assuming sex is binary and encoded as 1/0\n",
    "    return model_input\n",
    "\n",
    "\n",
    "optimized_profile, optimized_score = optimize_profiles(rf, initial_guess, iterations=5000)\n",
    "\n",
    "# Print the optimized profile and score\n",
    "print(\"Optimized Profile:\", optimized_profile)\n",
    "print(\"Optimized Predicted Success Rate:\", optimized_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of the random search algorithm is to find best combination of feature that maximisze success rate "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
